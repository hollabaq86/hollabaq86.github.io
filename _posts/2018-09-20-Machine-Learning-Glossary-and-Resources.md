---
author: xoxo Holla
---

_Encyclopedia Machina_

## Overview

Machine Learning(ML), as an area of focus in computer and data science, has a _lot_ of jargon that can send you down rabbit holes. It's definitely happened to me! So, with that in mind, I'm creating a directory of common terms, resources for extra learning, open source libraries that I've used and for what purpose, and my two cents on whether it's worth diving down that rabbit hole to know more. This post will most definitely be updated as I learn throughout my mentorship and beyond.

## TLDR/Getting started with ML as a concept

*I don't have a lot of time to read:* check out David Fumo's intro to different ML algorithms [here](https://towardsdatascience.com/types-of-machine-learning-algorithms-you-should-know-953a08248861).

*I have _some_ time to read:* 

- Adam Geitgey has a knack for making ML relatable, check out his [articles](https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471).

*I've got all the time to learn at my own pace:*

- Udacity has an [Intro to ML course](https://www.udacity.com/course/intro-to-machine-learning--ud120) that incorporates videos and relatable examples. _Word of advice, you may want to consider skipping through Chapters 1 & 2 unless you like lots of videos and clicking icons._

## Gimme all the terms!

* Supervised Learning- 
	*Fancy definition:*

	Supervised learning is usually mapping a set of inputs to an expectation of an output. How the inputs impact the output is determined by different methods (algorithms) depending on the data or your strategy.

	*My hot take:*

	I'm providing source data for my algorithm to train on, and I have a fair idea of how different parts of my data are related or interact, or a specific idea of what I want my result to be.

* Unsupervised Learning- 
	*Fancy definition:*

	Unsupervised learning is used to ascertain relationship between various nodes or data points without the help of extensive labelling/relationship mapping.

	* My hot take:*
	Help me Obi-Wan, I have all this information but I have no idea if there's any relationship or way to classify it into groups. You're my only hope! 

* Training set- a small set of data that is used by supervised algorithm to determine how inputs impact output.

* Model- the set of weighted inputs created by a ML algorithm that determins the output.

* Corpus- in natural language processing, this is a collection of texts used to train a ML algorithm.

* One Hot Encoding- a method used to denote categorical data in a binary way. [More information here](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f).

## Libraries! I want them all!

*For the command line*

* csvkit: a set of tools that are great for doing some csv munging or file-level changes on the command line.
* pandas: I've used this mostly for one hot encoding
* numpy: 
* scikit-learn:

## I want to start learning ML but I don't know what data I should study

Welcome to ze place for inspiration!

* [r/datasets](https://www.reddit.com/r/datasets/)
* [kaggle](https://www.kaggle.com)
* [Google's Dataset Search](https://toolbox.google.com/datasetsearch) *Note* They mention it's in beta, and for a reason. Most results are academic in origin
* [Chicago's Data Portal](https://data.cityofchicago.org) This is a new service created by the City of Chicago in an effort to be more transparent. See what you can find!
* [Make a FOIA request!](https://www.foia.gov/how-to.html) *Note* I wouldn't do this unless:
	- You can't find this data anywhere
	- You have time on your hands to wait for the results (especially if from the Fed gov't)
	- You're prepared to sue for this information (which is your right if you do not receive a response within a certain amount of time)







